{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script summarizes and visualizes the missing link prediction predictive performance results across the food web database. \n",
    "\n",
    "Requires the following results folders: 'Results_Food_Webs_0', 'Results_Food_Webs_1', 'Results_Food_Webs_2', 'Results_Food_Webs_3', 'Results_Food_Webs_4', 'Results_Food_Webs_Aggregated'\n",
    "\n",
    "Note this was run with Python 3.12.4, numpy 1.26.4, matplotlib 3.8.4, scipy 1.13.1, pandas 2.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import os\n",
    "import scipy.stats\n",
    "import pickle\n",
    "import summarize_results_food_webs\n",
    "import string\n",
    "import pandas as pd\n",
    "FONT_SIZE = 17\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.font_manager as font_manager\n",
    "font_dir = ['../../Helvetica']\n",
    "for font in font_manager.findSystemFonts(font_dir):\n",
    "    font_manager.fontManager.addfont(font)\n",
    "plt.rcParams['font.family'] = 'Helvetica'\n",
    "\n",
    "# short (in processed data) to long name (in results files) dictionary\n",
    "folder_shorter_names = {'Grand Caricaie Clmown1':'Grand Caricaie  marsh dominated by Cladietum marisci, mown  Clmown1',\\\n",
    "    'Grand Caricaie Clmown2': 'Grand Caricaie  marsh dominated by Cladietum marisci, mown  Clmown2',\\\n",
    "    'Grand Caricaie ClControl1': 'Grand Caricaie  marsh dominated by Cladietum marisci, not mown  ClControl1',\\\n",
    "    'Grand Caricaie ClControl2': 'Grand Caricaie  marsh dominated by Cladietum marisci, not mown  ClControl2',\\\n",
    "    'Grand Caricaie Scmown1': 'Grand Caricaie  marsh dominated by Schoenus nigricans, mown  Scmown1 ',\\\n",
    "    'Grand Caricaie Scmown2': 'Grand Caricaie  marsh dominated by Schoenus nigricans, mown  Scmown2 ',\\\n",
    "    'Grand Caricaie ScControl1': 'Grand Caricaie  marsh dominated by Schoenus nigricans, not mown  ScControl1 ',\\\n",
    "    'Grand Caricaie ScControl2': 'Grand Caricaie  marsh dominated by Schoenus nigricans, not mown  ScControl2 '}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results_Food_Webs_0\n",
      "count fully missing auc 0\n",
      "count missing some auc results 0\n",
      "count fully missing avp 0\n",
      "count missing some avp results 0\n",
      "food web ids to still run: []\n",
      "Results_Food_Webs_1\n",
      "count fully missing auc 0\n",
      "count missing some auc results 0\n",
      "count fully missing avp 0\n",
      "count missing some avp results 0\n",
      "food web ids to still run: []\n",
      "Results_Food_Webs_2\n",
      "count fully missing auc 0\n",
      "count missing some auc results 0\n",
      "count fully missing avp 0\n",
      "count missing some avp results 0\n",
      "food web ids to still run: []\n",
      "Results_Food_Webs_3\n",
      "count fully missing auc 0\n",
      "count missing some auc results 0\n",
      "count fully missing avp 0\n",
      "count missing some avp results 0\n",
      "food web ids to still run: []\n",
      "Results_Food_Webs_4\n",
      "count fully missing auc 0\n",
      "count missing some auc results 0\n",
      "count fully missing avp 0\n",
      "count missing some avp results 0\n",
      "food web ids to still run: []\n"
     ]
    }
   ],
   "source": [
    "# Check we got through all of the results\n",
    "num_it = 5\n",
    "num_webs = 290\n",
    "full_color = 'chocolate'\n",
    "struc_color = 'olivedrab'\n",
    "attr_color = 'cadetblue'\n",
    "\n",
    "Data_Folder = 'Processed_Data_Disaggregated_Lifestage'\n",
    "# These results correspond to those on Processed_Data_Disaggregated_Lifestage, Processed_Data_Disaggregated_Lifestage_1, \n",
    "# Processed_Data_Disaggregated_Lifestage_2, Processed_Data_Disaggregated_Lifestage_3, Processed_Data_Disaggregated_Lifestage_4\n",
    "Results_Folders = ['Results_Food_Webs_0', 'Results_Food_Webs_1', 'Results_Food_Webs_2', 'Results_Food_Webs_3', 'Results_Food_Webs_4']\n",
    "Figure_Folder = 'Figures'\n",
    "Processing_Folder = 'Data_Processing_Code_Disaggregated_Lifestage'\n",
    "\n",
    "if not os.path.exists(Figure_Folder):\n",
    "    os.mkdir(Figure_Folder)\n",
    "\n",
    "for res_folder in Results_Folders:\n",
    "    print(res_folder)\n",
    "    ids_to_skip = summarize_results_food_webs.check_all_results(Data_Folder, res_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Results_Food_Webs_0\\\\stacking_auc_Grand Caricaie ScControl1 _6.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res_folder \u001b[38;5;129;01min\u001b[39;00m Results_Folders:\n\u001b[1;32m----> 2\u001b[0m     summarize_results_food_webs\u001b[38;5;241m.\u001b[39mfood_web_result_to_file(Data_Folder, res_folder, num_it, ids_to_skip, folder_shorter_names)\n",
      "File \u001b[1;32m~\\Documents\\Research\\Link_Pred_1_Clean\\food_web_link_prediction\\Real_Networks\\summarize_results_food_webs.py:108\u001b[0m, in \u001b[0;36mfood_web_result_to_file\u001b[1;34m(folder, Results_Folder, num_it, ids_to_skip, folder_shorter_names)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fw_id \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ids_to_skip:\n\u001b[0;32m    107\u001b[0m     row_to_write \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(roc_out_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m sim_output, \u001b[38;5;28mopen\u001b[39m(pr_out_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m sim_output2:\n\u001b[0;32m    109\u001b[0m         sim_reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mreader(sim_output)\n\u001b[0;32m    110\u001b[0m         struc \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Results_Food_Webs_0\\\\stacking_auc_Grand Caricaie ScControl1 _6.csv'"
     ]
    }
   ],
   "source": [
    "for res_folder in Results_Folders:\n",
    "    summarize_results_food_webs.food_web_result_to_file(Data_Folder, res_folder, num_it, ids_to_skip, folder_shorter_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC-AUC results\n",
    "fig, ha = plt.subplots(2, 2, figsize=(15,10))\n",
    "num_it = 25\n",
    "sp = [(2,2,1),(2,2,3)]\n",
    "summarize_results_food_webs.food_web_result_plots(Data_Folder, Results_Folders,[],'Overall Average Performance',\\\n",
    "                                                  'auc', 'ROC', num_it, True, True, sp, False, num_webs, folder_shorter_names, FONT_SIZE,\\\n",
    "                                                 full_color, struc_color, attr_color)\n",
    "sp = [(2,2,2),(2,2,4)]\n",
    "summarize_results_food_webs.food_web_result_plots(Data_Folder, Results_Folders, [],'Overall Average Performance',\\\n",
    "                                                  'avp', 'PR', num_it, True, True, sp, False, num_webs, folder_shorter_names, FONT_SIZE,\\\n",
    "                                                 full_color, struc_color, attr_color)\n",
    "\n",
    "for n, ax in enumerate(ha.flat):\n",
    "    ax.text(-0.1, 1.1, string.ascii_lowercase[n], transform=ax.transAxes, size=FONT_SIZE, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{Figure_Folder}/Food_Web_Database_Overall.pdf',dpi=1000,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC-AUC results, broken up by ecosystem type\n",
    "fig, ha = plt.subplots(3, 2, figsize=(15,15))\n",
    "\n",
    "num_it = 25\n",
    "with open(os.path.join(Processing_Folder,'fw_metadata.pickle'), 'rb') as handle:\n",
    "    fw_metadata = pickle.load(handle)\n",
    "    \n",
    "i = 1\n",
    "for eco_type in ['lakes', 'marine','streams','terrestrial aboveground','terrestrial belowground']:\n",
    "    ids_to_skip = []\n",
    "    for fw in fw_metadata:\n",
    "        if fw_metadata[fw]['ecosystem.type'] != eco_type:\n",
    "            fw_id = str(fw_metadata[fw]['fw_id'])\n",
    "            if fw_id not in ids_to_skip:\n",
    "                ids_to_skip.append(fw_id)\n",
    "    num_skip = len(ids_to_skip)\n",
    "    print(f\"Ecosystem Type: {eco_type}\")\n",
    "    summarize_results_food_webs.food_web_result_plots(Data_Folder, Results_Folders, ids_to_skip, f'{eco_type} ({num_webs-num_skip})'.title(),\\\n",
    "                            'auc', 'ROC', num_it, False, True, [(3,2,i)], True, num_webs, folder_shorter_names, FONT_SIZE,\\\n",
    "                                                     full_color, struc_color, attr_color)\n",
    "    i+=1\n",
    "    \n",
    "ha[-1,-1].axis('off')\n",
    "for n, ax in enumerate(ha.flat[0:5]):\n",
    "    ax.text(-0.1, 1.1, string.ascii_lowercase[n], transform=ax.transAxes, size=FONT_SIZE, weight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{Figure_Folder}/Food_Web_ROC_AUC_Ecotype.pdf',dpi=1000,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PR-AUC results, broken up by ecosystem type\n",
    "fig, ha = plt.subplots(3, 2, figsize=(15,15))\n",
    "\n",
    "num_it = 25\n",
    "with open(os.path.join(Processing_Folder,'fw_metadata.pickle'), 'rb') as handle:\n",
    "    fw_metadata = pickle.load(handle)\n",
    "    \n",
    "i = 1\n",
    "for eco_type in ['lakes', 'marine','streams','terrestrial aboveground','terrestrial belowground']:\n",
    "    ids_to_skip = []\n",
    "    for fw in fw_metadata:\n",
    "        if fw_metadata[fw]['ecosystem.type'] != eco_type:\n",
    "            fw_id = str(fw_metadata[fw]['fw_id'])\n",
    "            if fw_id not in ids_to_skip:\n",
    "                ids_to_skip.append(fw_id)\n",
    "    num_skip = len(ids_to_skip)\n",
    "    print(f\"Ecosystem Type: {eco_type}\")\n",
    "    summarize_results_food_webs.food_web_result_plots(Data_Folder, Results_Folders, ids_to_skip,\\\n",
    "                          f'{eco_type} ({num_webs-num_skip})'.title(), 'avp', 'PR', num_it,\\\n",
    "                                                      False, True,[(3,2,i)], True, num_webs, folder_shorter_names, FONT_SIZE,\\\n",
    "                                                     full_color, struc_color, attr_color)\n",
    "    i+=1\n",
    "    \n",
    "ha[-1,-1].axis('off')\n",
    "for n, ax in enumerate(ha.flat[0:5]):\n",
    "    ax.text(-0.1, 1.1, string.ascii_lowercase[n], transform=ax.transAxes, size=FONT_SIZE, weight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{Figure_Folder}/Food_Web_PR_AUC_Ecotype.pdf',dpi=1000,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregated by life stage results\n",
    "num_it = 5\n",
    "num_webs = 290\n",
    "Data_Folder_Aggregated = 'Processed_Data_Aggregated_Lifestage'\n",
    "Results_Folders_Aggregated = ['Results_Food_Webs_Aggregated']\n",
    "ids_to_skip = summarize_results_food_webs.check_all_results(Data_Folder_Aggregated, Results_Folders_Aggregated[0])\n",
    "summarize_results_food_webs.food_web_result_to_file(Data_Folder_Aggregated, Results_Folders_Aggregated[0], num_it, ids_to_skip, folder_shorter_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results for the 25 food webs that change with aggregation\n",
    "fig, ha = plt.subplots(2, 2, figsize=(15,10))\n",
    "to_viz = ['Grand Caricaie  marsh dominated by Cladietum marisci, mown  Clmown1', 'Grand Caricaie  marsh dominated by Cladietum marisci, mown  Clmown2', 'Grand Caricaie  marsh dominated by Cladietum marisci, not mown  ClControl1', 'Grand Caricaie  marsh dominated by Cladietum marisci, not mown  ClControl2', 'Grand Caricaie  marsh dominated by Schoenus nigricans, mown  Scmown1 ', 'Grand Caricaie  marsh dominated by Schoenus nigricans, mown  Scmown2 ', 'Grand Caricaie  marsh dominated by Schoenus nigricans, not mown  ScControl1 ', 'Grand Caricaie  marsh dominated by Schoenus nigricans, not mown  ScControl2 ', 'Chesapeake Bay', 'Carpinteria', 'Hardknott Gill', 'Mill Stream', 'Gearagh', 'Dutch Microfauna food web PlotA', 'Dutch Microfauna food web PlotB', 'Dutch Microfauna food web PlotC', 'Broad Stream', 'Canton Creek', 'Dempsters Stream', 'German Creek', 'Healy Creek', 'Kye Burn', 'Little Kye Burn', 'Stony Stream', 'Skipwith Pond']\n",
    "with open(os.path.join('Processed_Data_Disaggregated_Lifestage','fw_ids.pickle'),'rb') as f:\n",
    "    fw_ids_dis = pickle.load(f)\n",
    "to_viz_ids_dis = []\n",
    "for fw_name in to_viz:\n",
    "        to_viz_ids_dis.append(fw_ids_dis[fw_name])\n",
    "with open(os.path.join('Processed_Data_Aggregated_Lifestage','fw_ids.pickle'),'rb') as f:\n",
    "    fw_ids_agg = pickle.load(f)\n",
    "to_viz_ids_agg = []\n",
    "for fw_name in to_viz:\n",
    "        to_viz_ids_agg.append(fw_ids_agg[fw_name])\n",
    "assert to_viz_ids_dis == to_viz_ids_agg, \"not same ids\"\n",
    "\n",
    "to_skip = []\n",
    "for i in range(0,290):\n",
    "    if i not in to_viz_ids_dis:\n",
    "        to_skip.append(str(i))\n",
    "\n",
    "print(to_skip)\n",
    "\n",
    "# Disaggregated results, filtered down to that 25 - ROC AUC\n",
    "summarize_results_food_webs.food_web_result_plots(Data_Folder, Results_Folders, to_skip,'Disaggregated',\\\n",
    "                      'auc', 'ROC', 25, True, True, [(2,2,1)], True, num_webs, folder_shorter_names, FONT_SIZE,\\\n",
    "                                                 full_color, struc_color, attr_color)\n",
    "\n",
    "# Disaggregated results, filtered down to that 25 - PR AUC\n",
    "summarize_results_food_webs.food_web_result_plots(Data_Folder, Results_Folders, to_skip,'Disaggregated',\\\n",
    "                      'avp', 'PR', 25, True, True, [(2,2,2)], True,  num_webs, folder_shorter_names, FONT_SIZE,\\\n",
    "                                                 full_color, struc_color, attr_color)\n",
    "\n",
    "# Aggregated results, filtered down to that 25 - ROC AUC\n",
    "summarize_results_food_webs.food_web_result_plots(Data_Folder_Aggregated, Results_Folders_Aggregated, to_skip,'Aggregated',\\\n",
    "                      'auc', 'ROC', 5, True, True, [(2,2,3)],True,  num_webs, folder_shorter_names, FONT_SIZE,\\\n",
    "                                                 full_color, struc_color, attr_color)\n",
    "\n",
    "# Aggregated results, filtered down to that 25 - PR AUC\n",
    "summarize_results_food_webs.food_web_result_plots(Data_Folder_Aggregated, Results_Folders_Aggregated, to_skip,'Aggregated',\\\n",
    "                      'avp', 'PR', 5, True, True, [(2,2,4)],True,  num_webs, folder_shorter_names, FONT_SIZE,\\\n",
    "                                                 full_color, struc_color, attr_color)\n",
    "\n",
    "for n, ax in enumerate(ha.flat):\n",
    "    ax.text(-0.1, 1.1, string.ascii_lowercase[n], transform=ax.transAxes, size=FONT_SIZE, weight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{Figure_Folder}/Food_Web_Supplemental_Aggregated.pdf',dpi=1000,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all the summary results files into one (average across all iterations for a food web / model)\n",
    "ct = 0 \n",
    "for res in Results_Folders:\n",
    "    if ct == 0:\n",
    "        summary_df = pd.read_csv(os.path.join(res,f'food_web_lp_res_{res}.csv'))\n",
    "    else:\n",
    "        summary_df = pd.concat((summary_df, pd.read_csv(os.path.join(res,f'food_web_lp_res_{res}.csv'))))\n",
    "    ct += 1\n",
    "grouped_df = summary_df.groupby('net_id').mean()\n",
    "grouped_df.to_csv(os.path.join('Summarized_Results',f'food_web_lp_res.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
